# -*- coding: utf-8 -*-
"""Project329.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GcUszqknTo4XhG4s3Ld81hVrfj6ynwFu
"""

#Imports
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout, BatchNormalization, ReLU
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from keras.utils import to_categorical
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences

#Downloads
nltk.download('punkt')
nltk.download('stopwords')
df = pd.read_csv('/content/emotion.csv')

#EDA
df.head()

#Shape of data
df.shape

#Get label counts
df.label.value_counts()

#Check for null values
df.isnull().sum() #NA

#Restructre data
df.rename(columns={'text': 'Text', 'label': 'Label'}, inplace=True)
# Dropping the Index Colums
df.drop('Unnamed: 0',axis=1,inplace=True)
#0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'
df['Label'] = df['Label'].replace(0,'Sadness')
df['Label'] = df['Label'].replace(1,'Joy')
df['Label'] = df['Label'].replace(2,'Love')
df['Label'] = df['Label'].replace(3,'Anger')
df['Label'] = df['Label'].replace(4,'Fear')
df['Label'] = df['Label'].replace(5,'Surprise')
df.head()

#Data visualization

#Create a bar plot
count = df['Label'].value_counts()
plt.figure(figsize=(8, 6))
sns.barplot(x=count.index, y=count.values, palette="viridis")
plt.title('Count of Each Label')
plt.xlabel('Label')
plt.ylabel('Count')
plt.show()

# Count label distributions
label_counts = df['Label'].value_counts()
light_colors = sns.husl_palette(n_colors=len(label_counts))
sns.set(style="whitegrid")
plt.figure(figsize=(8, 8))
plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', startangle=140, colors=light_colors)
plt.title('Emotion Test Distribution')
plt.show()

#Data Cleaning
#Remove URLs
df['Text'] = df['Text'].str.replace(r'http\S+', '', regex=True)

#Remove extra whitespaces
df['Text'] = df['Text'].str.replace(r'\s+', ' ', regex=True)

#Remove numeric values
df['Text'] = df['Text'].str.replace(r'\d+', '', regex=True)

#Remove special characters and punctuation
df['Text'] = df['Text'].str.replace(r'[^\w\s]', '', regex=True)

#Lowercasing
df['Text'] = df['Text'].str.lower()

#Remove stop words
stop = stopwords.words('english')
df["Text"] = df['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

#Check
print(df.head())

#Remove abbreviated words

with open('extracted_words.txt', 'r', encoding='utf-8') as file:
    extracted_words = {word.strip() for word in file.readlines()}

def remove_extracted_words(text):
    words = text.split()
    filtered_words = [word for word in words if word.lower() not in extracted_words]
    return ' '.join(filtered_words)


df['Text'] = df['Text'].apply(remove_extracted_words)


#Check
print(df.head())

pip install emoji

#emojis to text
import emoji
df["Text"] = df['Text'].apply(lambda x: emoji.demojize(x))

#pick 14000 rows respectively for every emotions
joy = df[df['Label'] == 'Joy'].sample(n=14000, random_state=20)
sadness = df[df['Label'] == 'Sadness'].sample(n=14000, random_state=20)
fear = df[df['Label'] == 'Fear'].sample(n=14000, random_state=20)
anger = df[df['Label'] == 'Anger'].sample(n=14000, random_state=20)
love = df[df['Label'] == 'Love'].sample(n=14000, random_state=20)
surprise = df[df['Label'] == 'Surprise'].sample(n=14000, random_state=20)
df_sampled = pd.concat([joy, sadness, fear, anger,love,surprise])

df = df_sampled.sample(frac=1, random_state=20).reset_index(drop=True)

df.Label.value_counts()

print(df.head())

#Split data into X, y
texts = df['Text']
labels = df['Label']

#encoding labels
label_map = {'Sadness': 0, 'Joy': 1, 'Love': 2, 'Anger': 3, 'Fear': 4, 'Surprise': 5}
labels = [label_map[label] for label in labels]
labels = np.array(labels)
labels = to_categorical(labels, num_classes=6)
labels.shape

#tokenization and pad sequences
tokenizer = Tokenizer(num_words=10000)
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)

texts = pad_sequences(sequences, maxlen=50)

#Split data into training (70%), development (15%), and test (15%)sets

x_train, x_temp, y_train, y_temp = train_test_split(texts, labels, test_size=0.3, random_state=42)
x_dev, x_test, y_dev, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

print('Training set size:', len(x_train))
print('Development set size:', len(x_dev))
print('Test set size:', len(x_test))

max_words = 10000
max_len = 50
embedding_dim = 32

# Build the CNN model
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, BatchNormalization, Dense
model = Sequential()
model.add(Embedding(max_words, embedding_dim, input_length=max_len))
model.add(Conv1D(64, 3, padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(ReLU())
model.add(Dropout(.5))
model.add(GlobalMaxPooling1D(keepdims=True))
model.add(Conv1D(64, 3, padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(ReLU())
model.add(Dropout(.5))
model.add(GlobalMaxPooling1D())
model.add(Dense(128, activation='relu'))
model.add(Dropout(.5))
model.add(Dense(6, activation='softmax'))

# Compile the cnn model
optimizer = Adam(learning_rate=0.001)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Print cnn model summary
model.summary()

# Train the cnn model
batch_size = 256
epochs = 25

history=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)

#Evaluate the cnn model for training dataset
# Evaluate the model
loss, accuracy = model.evaluate(x_train, y_train)

# Make predictions
y_pred = model.predict(x_train)
y_pred = np.argmax(y_pred, axis=1)  # Convert one-hot predictions back to labels
y_train= np.argmax(y_train, axis=1)
# Calculate precision and recall
precision = precision_score(y_train, y_pred, average='macro')  # Calculate precision
recall = recall_score(y_train, y_pred, average='macro')  # Calculate recall

# Print evaluation metrics
print(f'Loss: {round(loss, 2)}, Accuracy: {round(accuracy, 2)}, Precision: {round(precision, 2)}, Recall: {round(recall, 2)}')

# Evaluate the cnn model for testing dataset
loss, accuracy = model.evaluate(x_test, y_test)

# Make predictions
y_pred = model.predict(x_test)
y_pred = np.argmax(y_pred, axis=1)  # Convert one-hot predictions back to labels
y_test= np.argmax(y_test, axis=1)
# Calculate precision and recall
precision = precision_score(y_test, y_pred, average='macro')  # Calculate precision
recall = recall_score(y_test, y_pred, average='macro')  # Calculate recall

# Print evaluation metrics
print(f'Loss: {round(loss, 2)}, Accuracy: {round(accuracy, 2)}, Precision: {round(precision, 2)}, Recall: {round(recall, 2)}')

print(history.history.keys())

plt.plot(history.history['loss'])
plt.plot(history.history['accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

#LSTM
import numpy as np
import pandas as pd

from nltk.corpus import stopwords
import re
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Embedding, LSTM, Dense
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping

# Load CSV dataset
data = pd.read_csv("text.csv")

#Data Cleaning
#Remove URLs
data['text'] = data['text'].str.replace(r'http\S+', '', regex=True)

#Remove extra whitespaces
data['text'] = data['text'].str.replace(r'\s+', ' ', regex=True)

#Remove numeric values
data['text'] = data['text'].str.replace(r'\d+', '', regex=True)

#Remove special characters and punctuation
data['text'] = data['text'].str.replace(r'[^\w\s]', '', regex=True)

#Lowercasing
data['text'] = data['text'].str.lower()

#Remove stop words
stop = stopwords.words('english')
data["text"] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
#Chat words
data["text"] = data['text'].apply(lambda x: re.sub(r'LOL', 'laughing out loud', x, flags=re.IGNORECASE))
data["text"] = data['text'].apply(lambda x: re.sub(r'BRB', 'be right back', x, flags=re.IGNORECASE))


# Down Sample 14,000 rows from each label
data_sampled = data.groupby('label').apply(lambda x: x.sample(n=14000)).reset_index(drop=True)
X = data_sampled['text']
y = data_sampled['label']

# Tokenization
tokenizer = Tokenizer()
tokenizer.fit_on_texts(X)
X = tokenizer.texts_to_sequences(X)

# Padding sequences
maxlen = max(len(x) for x in X)
X = pad_sequences(X, maxlen=maxlen)

# Convert labels to categorical
y = to_categorical(y)

# Train-dev-test split (70-15-15)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# word embeddings
embedding_dim = 100
word_index = tokenizer.word_index
num_words = len(word_index) + 1

# Build LSTM model
model = Sequential()
model.add(Embedding(num_words, 100, input_length=maxlen))
model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(6, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
history = model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=20, batch_size=128, callbacks=[early_stopping])

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)
# Predict probabilities on the test set
probabilities = model.predict(X_test)

# Identify uncertain and confident predictions
threshold = 0.8  # Adjust as needed
uncertain_indices = []
confident_indices = []
for i, prob in enumerate(probabilities):
    max_prob = np.max(prob)
    if max_prob < threshold:
        uncertain_indices.append(i)
    else:
        confident_indices.append(i)
# Extract labels of the test set
y_test_labels = np.argmax(y_test, axis=1)
uncertain_labels = y_test_labels[uncertain_indices]
confident_labels = y_test_labels[confident_indices]
label_0 = 0
label_1 = 0
label_2 = 0
label_3 = 0
label_4 = 0
label_5 = 0
c_label_0 = 0
c_label_1 = 0
c_label_2 = 0
c_label_3 = 0
c_label_4 = 0
c_label_5 = 0
for labels in uncertain_labels:
    if labels == 0:
        label_0 = label_0 + 1
    if labels == 1:
        label_1 = label_1 + 1
    if labels == 2:
        label_2 = label_2 + 1
    if labels == 3:
        label_3 = label_3 + 1
    if labels == 4:
        label_4 = label_4 + 1
    if labels == 5:
        label_4 = label_5 + 1
for c_labels in confident_labels:
    if c_labels == 0:
        c_label_0 = c_label_0 + 1
    if c_labels == 1:
        c_label_1 = c_label_1 + 1
    if c_labels == 2:
        c_label_2 = c_label_2 + 1
    if c_labels == 3:
        c_label_3 = c_label_3 + 1
    if c_labels == 4:
        c_label_4 = c_label_4 + 1
    if c_labels == 5:
        c_label_4 = c_label_5 + 1

# Print indices of uncertain and confident predictions
print("uncertain predictions of label 0:", label_0)
print("uncertain predictions of label 1:", label_1)
print("uncertain predictions of label 2:", label_2)
print("uncertain predictions of label 3:", label_3)
print("uncertain predictions of label 4:", label_4)
print("uncertain predictions of label 5:", label_5)
print("confident predictions of label 0:", c_label_0)
print("confident predictions of label 1:", c_label_1)
print("confident predictions of label 2:", c_label_2)
print("confident predictions of label 3:", c_label_3)
print("confident predictions of label 4:", c_label_4)
print("confident predictions of label 5:", c_label_5)
# Predict labels for the test data
predictions = model.predict(X_test)

# Extract true labels from one-hot encoded format
true_labels = np.argmax(y_test, axis=1)

# Initialize dictionaries to store counts and accuracies for each emotion
emotion_counts = {}
emotion_accuracies = {}

# Calculate counts and accuracies for each emotion
for emotion in range(6):
    correct_count = 0
    total_count = 0


    for i in range(len(predictions)):
        if true_labels[i] == emotion:
            total_count += 1
            predicted_label = np.argmax(predictions[i])
            if predicted_label == emotion:
                correct_count += 1

    # Calculate accuracy for the emotion
    accuracy = correct_count / total_count if total_count > 0 else 0

    # Store counts and accuracies in dictionaries
    emotion_counts[emotion] = total_count
    emotion_accuracies[emotion] = accuracy

# Print accuracies for each emotion
for emotion, accuracy in emotion_accuracies.items():
    print(f"Accuracy for emotion {emotion}: {accuracy:.2f} ({emotion_counts[emotion]} instances)")

from sklearn.feature_extraction.text import TfidfVectorizer
#Downloads
nltk.download('punkt')
nltk.download('stopwords')
df = pd.read_csv('text.csv')

#Data Cleaning
df.rename(columns={'text': 'Text', 'label': 'Label'}, inplace=True)
# Dropping the Index Colums
df.drop('Unnamed: 0',axis=1,inplace=True)
#0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'
df['Label'] = df['Label'].replace(0,'Sadness')
df['Label'] = df['Label'].replace(1,'Joy')
df['Label'] = df['Label'].replace(2,'Love')
df['Label'] = df['Label'].replace(3,'Anger')
df['Label'] = df['Label'].replace(4,'Fear')
df['Label'] = df['Label'].replace(5,'Surprise')
df.head()

#Remove URLs
df['Text'] = df['Text'].str.replace(r'http\S+', '', regex=True)

#Remove extra whitespaces
df['Text'] = df['Text'].str.replace(r'\s+', ' ', regex=True)

#Remove numeric values
df['Text'] = df['Text'].str.replace(r'\d+', '', regex=True)

#Remove special characters and punctuation
df['Text'] = df['Text'].str.replace(r'[^\w\s]', '', regex=True)

#Lowercasing
df['Text'] = df['Text'].str.lower()

#Remove stop words
stop = stopwords.words('english')
df["Text"] = df['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

#Check
print(df.head())
pd.set_option('display.max_colwidth', 80)
examples = df.groupby('Label').first()
print(examples)


#Training/Development/Test Split - Select 14,000 rows for each label at random
df2 = pd.DataFrame(df)
selected_data = pd.DataFrame()

for label in df['Label'].unique():
    label_data = df[df['Label'] == label]
    selected_data = pd.concat([selected_data, label_data.sample(n=14000, replace=True, random_state=42)])

#Shuffle the selected data
selected_data = selected_data.sample(frac=1, random_state=42).reset_index(drop=True)

#Split into train, development, and test sets
train_size = int(len(selected_data) * 0.7)
dev_size = int(len(selected_data) * 0.15)

train_data = selected_data[:train_size]
dev_data = selected_data[train_size:train_size+dev_size]
test_data = selected_data[train_size+dev_size:]

print("Train set size:", len(train_data))
print("Development set size:", len(dev_data))
print("Test set size:", len(test_data))


# Feature Extraction
vectorizer = TfidfVectorizer(max_features=1000)
X_train = vectorizer.fit_transform(train_data['Text'])
X_dev = vectorizer.transform(dev_data['Text'])
X_test = vectorizer.transform(test_data['Text'])

# Encode labels
label_to_index = {'Sadness': 0, 'Joy': 1, 'Love': 2, 'Anger': 3, 'Fear': 4, 'Surprise': 5}
y_train = train_data['Label'].map(label_to_index)
y_dev = dev_data['Label'].map(label_to_index)
y_test = test_data['Label'].map(label_to_index)

from sklearn.model_selection import GridSearchCV
#Basline Models
#Logistic Regression
logistic_model = LogisticRegression(max_iter=1000)
logistic_model.fit(X_train, y_train)
test_predictions = logistic_model.predict(X_test)
print("Testing Set Performance - Logistic Regression:")
print(classification_report(y_test, test_predictions))

#Multinomial Naive Bayes
naive_bayes_model = MultinomialNB()
naive_bayes_model.fit(X_train, y_train)
test_predictions = naive_bayes_model.predict(X_test)
print("Testing Set Performance:")
print(classification_report(y_test, test_predictions))


#Hyperparameter Tuning Logistic Regression A - Isabel
hyperparameters = {
    'C': 10,
    'penalty': 'l2',
    'solver': 'lbfgs',
    'class_weight': 'balanced',
    'max_iter': 1000}

logreg_model = LogisticRegression(**hyperparameters)
logreg_model.fit(X_train, y_train)

train_accuracy = logreg_model.score(X_train, y_train)
dev_accuracy = logreg_model.score(X_dev, dev_data['Label'].map(label_to_index))
test_accuracy = logreg_model.score(X_test, y_test)

print("Train Accuracy:", train_accuracy)
print("Dev Accuracy:", dev_accuracy)
print("Test Accuracy:", test_accuracy)
print("Hyperparameters:", hyperparameters)



#Hyperparameter Tuning Naive Bayes
param_grid = {
    'alpha': [0.1, 0.5, 1.0, 2.0],
    'fit_prior': [True, False]
}

grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

# Model Evaluation
dev_predictions = best_model.predict(X_dev)
test_predictions = best_model.predict(X_test)

dev_classification_report = classification_report(y_dev, dev_predictions)
test_classification_report = classification_report(y_test, test_predictions)

print("Development Set Performance:")
print(dev_classification_report)
print("Test Set Performance:")
print(test_classification_report)
print("Best Parameters:", grid_search.best_params_)

import random
import math
#Logistic regression model B includes stop words, special characters and punctuation
df_logB = pd.read_csv('text.csv')

#Restructure data
df_logB.rename(columns={'text': 'Text', 'label': 'Label'}, inplace=True)
#Dropping the Index Columns
df_logB.drop('Unnamed: 0', axis=1, inplace=True)
#0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'
df_logB['Label'] = df_logB['Label'].replace({
    0: 'Sadness', 1: 'Joy', 2: 'Love', 3: 'Anger', 4: 'Fear', 5: 'Surprise'
})

#Data Cleaning
#Remove URLs
df_logB['Text'] = df_logB['Text'].str.replace(r'http\S+', '', regex=True)

#Remove extra whitespaces
df_logB['Text'] = df_logB['Text'].str.replace(r'\s+', ' ', regex=True)

#Remove numeric values
df_logB['Text'] = df_logB['Text'].str.replace(r'\d+', '', regex=True)

#Lowercasing
df_logB['Text'] = df_logB['Text'].str.lower()

#Check
print(df_logB.head())

#repeated for logistic regression B data
df_logB["Text"] = df_logB['Text'].apply(lambda x: emoji.demojize(x))

#repeated for logistic regression B data

joy = df_logB[df_logB['Label'] == 'Joy'].sample(n=14000, random_state=20)
sadness = df_logB[df_logB['Label'] == 'Sadness'].sample(n=14000, random_state=20)
fear = df_logB[df_logB['Label'] == 'Fear'].sample(n=14000, random_state=20)
anger = df_logB[df_logB['Label'] == 'Anger'].sample(n=14000, random_state=20)
love = df_logB[df_logB['Label'] == 'Love'].sample(n=14000, random_state=20)
surprise = df_logB[df_logB['Label'] == 'Surprise'].sample(n=14000, random_state=20)
df_logB_samp = pd.concat([joy, sadness, fear, anger,love,surprise])

df_logB = df_logB_samp.sample(frac=1, random_state=20).reset_index(drop=True)
df_logB.Label.value_counts()
print(df_logB.head())
#Logistic Regression Model B: includes stop words, punctuation and special characters
category_counts = df_logB['Label'].value_counts()
random.seed(42)
#shuffle
df_logB = df_logB.sample(frac=1).reset_index(drop=True)

rows_per_emo = 14000
prop = (category_counts-category_counts)+rows_per_emo
# Initialize an empty DataFrame to store the selected rows
selected_rows = pd.DataFrame(columns=df_logB.columns)

# Select rows from each label
for label, count in prop.items():
    label_rows = df_logB[df_logB['Label'] == label].head(int(count))
    selected_rows = pd.concat([selected_rows, label_rows])

# Reset index for the selected rows
df_logB = selected_rows.reset_index(drop=True)

rows = rows_per_emo*6

train_prop = 0.7
dev_prop = 0.15
test_prop = 1 - train_prop - dev_prop

train_size = int(train_prop * rows)
dev_size = math.ceil(dev_prop * rows)
test_size = rows - train_size - dev_size

df_logB = df_logB.sample(frac=1).reset_index(drop=True)
train = df_logB[:train_size]
dev = df_logB[train_size:train_size + dev_size]
test = df_logB[train_size + dev_size:]


from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(max_features=10000)

#classifier
classifier = LogisticRegression()
train_X = vectorizer.fit_transform(train['Text'])
train_y = train['Label']
classifier.fit(train_X, train_y)

from sklearn.metrics import accuracy_score
#predict on development set
dev_text = dev['Text'].values
dev_X = vectorizer.transform(dev_text)
dev_y = dev['Label']

predictions = classifier.predict(dev_X)
acc = accuracy_score(dev_y, predictions)
print('Development accuracy = = {:.2f}%'.format(acc * 100))
#Logistic Regression Model B: includes stop words, punctuation and special characters
#adjust hyperparameters
hyperparameters = {
    'C': 1,
    'penalty': 'l1',
    'solver': 'liblinear',
    'max_iter': 1000,
    'class_weight': None
}

best_classifier = LogisticRegression(**hyperparameters)
best_classifier.fit(train_X, train_y)

predictions = best_classifier.predict(dev_X)
acc = accuracy_score(dev_y, predictions)
print('Development accuracy = = {:.2f}%'.format(acc * 100))

test_text = test['Text'].values
x_test = vectorizer.transform(test_text)
y_test = test['Label']

predictions = best_classifier.predict(x_test)
acc = accuracy_score(y_test, predictions)
print('Test accuracy = = {:.2f}%'.format(acc * 100))

"""RNN Model"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Embedding
from tensorflow.keras.models import Sequential
from keras.preprocessing.text import Tokenizer
from keras.utils import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping

#Downloads
nltk.download('punkt')
nltk.download('stopwords')
df = pd.read_csv('text.csv')

#Data Cleaning
df.rename(columns={'text': 'Text', 'label': 'Label'}, inplace=True)
# Dropping the Index Colums
df.drop('Unnamed: 0',axis=1,inplace=True)

#Remove URLs
df['Text'] = df['Text'].str.replace(r'http\S+', '', regex=True)

#Remove extra whitespaces
df['Text'] = df['Text'].str.replace(r'\s+', ' ', regex=True)

#Remove numeric values
df['Text'] = df['Text'].str.replace(r'\d+', '', regex=True)

#Remove special characters and punctuation
df['Text'] = df['Text'].str.replace(r'[^\w\s]', '', regex=True)

#Lowercasing
df['Text'] = df['Text'].str.lower()

#Remove stop words
stop = stopwords.words('english')
df["Text"] = df['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

tokenizer = Tokenizer(num_words = 1000, lower = True) #want 1000 most frequent words, lowercase = True
tokenizer.fit_on_texts(df["Text"].values)
X_tokens = tokenizer.texts_to_sequences(df["Text"].values) #sequence of numbers

#Vocab length
vocab_length= len(tokenizer.word_index) + 1

max = 0
for k in X_tokens:
    if len(k) > max:
        max = len(k)

print(f"The max length of reviews is {max}")

sequences = pad_sequences(X_tokens, maxlen = max)

#Splitting up into train, development, test
X_train, X_test, y_train, y_test = train_test_split(sequences, df["Label"], train_size= .70)
X_test, X_dev, y_test, y_dev = train_test_split(X_test, y_test, train_size= .50)

# using dense vectors to embed words - each word represented by 100 numbers
embedding_length = 100

#Building the model
# vocab length = how many unique words are in the training
# embedding length = output vector length
# input_length = input vector length
RNN_model = Sequential(name = "Simple_RNN")
RNN_model.add(Embedding(vocab_length, embedding_length, input_length = max))
RNN_model.add(SimpleRNN(128, dropout = 0.2, recurrent_dropout= 0.2))
RNN_model.add(Dense(6, activation = 'softmax'))

print(RNN_model.summary())

RNN_model.compile(loss = "sparse_categorical_crossentropy", optimizer = 'adam', metrics = ['accuracy'])

history = RNN_model.fit(X_train, y_train, batch_size= 128, epochs = 20 ,validation_data= (X_dev, y_dev), verbose = 1, callbacks = EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001))

results=RNN_model.evaluate(X_test,y_test)
print(results)